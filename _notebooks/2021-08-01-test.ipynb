{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"NBA Injury Report Sports Analytics Project (Part 1)\"\n",
    "> \"Introduction and setup for how to structure a complete sports analytics project\"\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- author Jeremy Abramson\n",
    "- categories: [sports analytics, nba, python, research, projects, injuries]\n",
    "- image: images/chart-preview.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Fooooootnote{% fn 100 %}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How To Read This Post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "It all started with a tweet from basketball analytics legend and Korean cinema aficionado [Ed Kupfer](https://twitter.com/EdKupfer):\n",
    "> twitter: https://twitter.com/EdKupfer/status/1385682808174256129\n",
    "\n",
    "\n",
    "Pretty straightforward, right?\n",
    "\n",
    "# Kickstarter Modelâ„¢ï¸ Goals\n",
    "As per The Kickstarter Modelâ„¢ï¸, we need to define our three goals.\n",
    "At first blush, we might suggest something like the following:\n",
    "- Fallback Goal: \"Get the PDFs\"\n",
    "- Baseline Goal: \"Extract data from the PDFs\"\n",
    "- Stretch Goal: \"Present the data somehow\"\n",
    "\n",
    "That's absolutely defensible, and has the bonus of structurally aligning with the major technical \"tasks\" of the project.\n",
    "But I'm not sure a directory full of PDFs qualifies as a \"dataset\" you could pass on to someone else as a contribution.\n",
    "Instead, we'll go with a slightly different approach (but feel free to use the above if it works better for you)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fallback Goal\n",
    "> Download and \"lift\" the data from the NBA Injury Report PDFs into some sort of machine-readable format (`CSV`, `JSON`, etc.)\n",
    "\n",
    "Since \"getting the data\" is kind of the main point of this entire exercise, even though extracting data from the PDFs requires requires some [at this point] unknown tooling, we're going to have both downloading *and* processing the PDFs be be our Fallback Goal.\n",
    "If we don't do anything else, or if nothing else \"works\", at least we'll have accomplished something useful that we can share with the community."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Baseline Goal\n",
    "> Present the data we obtained above in some sort of webapp/dashboard/etc.\n",
    "\n",
    "Structuring things this way now aligns with what we normally consider a \"Baseline\" Goal: A fully-fledged \"deliverable\" of some sort that provides value to the community.\n",
    "Doing this may sound a bit aggressive in terms of complexity, but our \"webapp\" doesn't need to be all that fancy.\n",
    "It's just a \"skin\" to slice and dice the data we generate from the Fallback Goal.\n",
    "It *should* be reasonably straightforward{% fn 1 %}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Stretch Goal\n",
    "> None\n",
    "\n",
    "As we were pretty aggressive with our first two goals, I think it's perfectly reasonable to not have a Stretch Goal.\n",
    "Normally, you might think to say something vague like \"analyze the injury data\", but in my opinion, that's actually *counterproductive*.\n",
    "The reason being that the goal of this project isn't really analysis!\n",
    "The goal is is unlock some data in one format, and present it to \"the user\" in another format that's more amenable for *their* absorption.  \n",
    "This may not sound very \"sexy\", but the reality is that this data collection/\"chewing\"/presenting process is basically [one of the most important things](https://www.sportperformanceanalysis.com/article/communication-with-coaches-as-a-performance-analyst) in sports analytics.\n",
    "So unless you have a *specific* analysis in mind, I think it makes sense to not have a Stretch Goal, and to just focus on the first two goals.\n",
    "If we do this right, perhaps something interesting will fall out of our dashboard, and we can explore it at that point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: Again, the point of setting these goals isn't to spur endless debate or to create another roadblock to starting a project.  It's just a way of structuring potential future design decisions, and making sure things like feature creep and \"great-being-the-enemy-of-good\" don't impede actually delivering on the goals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a conceptual goal framework in which to work, let's get to it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fallback Goal: Downloading and Processing NBA Injury Report PDFs\n",
    "\n",
    "The Kickstarter Modelâ„¢ï¸ is there to help us structure our effort wisely, and make productive high level design decisions, but it doesn't really say anything about *how* to do whatever it is we want to do!\n",
    "To that end, once we have our goals, I find it's helpful to spend a little time â€” *before* coding! â€” structuring my thinking about each of the tasks at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divvying Up Tasks\n",
    "As per the discussion above, for our Fallback Goal, it seems like we already have two \"high level\" tasks: \n",
    "\n",
    "1. Downloading PDFs\n",
    "2. Processing PDFs.\n",
    "\n",
    "But we can break those down a little further.\n",
    "First off, we can't download anything without knowing *what* to download.\n",
    "Ed's tweet mentions \"just change the date\", it seems safe to assume we'll need to build a list of URLs based on dates, unless there's some central page with links to all of the injury reports, in which case we can just scrape the URLs from that.\n",
    "\n",
    "And, of course, at this point I'm not sure exactly how to extract the data from the PDFs (minor detail, right?!?)\n",
    "But I'm pretty confident it *can* be done, so we'll save a little \"Google-fu\" for later.\n",
    "However, it does seem reasonable to use `Pandas` to post-process our data once we do get it out of the PDF, since it's definitely going to be tabular.\n",
    "Lastly, we might want to fancy with [asynchronous requests](https://www.twilio.com/blog/asynchronous-http-requests-in-python-with-aiohttp) (or perhaps not!  It might not be worth the effort, but let's note it here).\n",
    "\n",
    "Taking all of the above into account, our **Fallback Goal** task outline might look like this:\n",
    "\n",
    "1. Download PDFs\n",
    "    1. Generate list of URLs (dates) to injury report PDFs\n",
    "    2. Download URLs from list (do this asynchronously?)\n",
    "2.  Process PDFs\n",
    "    1. Extract data from PDF (with what?)\n",
    "    2. Post-process data (Pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tip: One thing we'll find as we progress is that this outline, as pedantic as it may seem, is incomplete.  Digging into the above steps, we'll invariably find places where the sub-steps aren't necessarily or obviously entailed by the macro steps.  If this gets too far out of hand â€” when, exactly, this happens is a bit of a judgment call â€” it makes sense to go back and revise the outline.  For the sake of this blog post, I'm going to go forward with this level of granularity, and we'll see how far we can get."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can tackle these individually, and make sure we're always progressing toward the end goal!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Downloading The Injury Reports\n",
    "\n",
    "Before we can actually do anything interesting with the injury reports, we need to download them.\n",
    "To do that, we need to know where there are.\n",
    "After some brief googling, it seems like there really isn't a central repository for these reports, and they're just uploaded one at a time{% fn 2 %}.\n",
    "\n",
    "\n",
    "The one example URL from Ed's tweet looks like this:\n",
    "> `https://ak-static.cms.nba.com/referee/injury/Injury-Report_2021-04-23_01PM.pdf`\n",
    "\n",
    "\n",
    "Seems like there's 4 parts to the URL:\n",
    "1. Some boilerplate: `https://ak-static.cms.nba.com/referee/injury/Injury-Report_`\n",
    "2. A date: `2021-04-23`\n",
    "3. A time: `01PM`\n",
    "4. The file extension: `.pdf`\n",
    "\n",
    "We're only interested in the middle two (the date and the time), as the boilerplate URL and the file extension won't change.  From googling{% fn 30 %} `\"nba injury report\"` and clicking on [the second link](https://official.nba.com/nba-injury-report-2020-21-season/) it seems like the times may be `1:30 PM`, `5:30 PM` and `8:30 PM`.\n",
    "Although from Ed's example, we see a `01PM` time in the URL, *not* `1:30`. \n",
    "So we'll go ahead and assume the appropriate times URL-wise are `01PM`, `05PM` and `08PM`.  \n",
    "Lastly, for simplicity, let's just focus on the `8:30PM` (or `8PM`, in URL-speak) file, as it's likely to be the most complete.\n",
    "We can download the rest later if we want.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a List of URLs to Download\n",
    "Google helped us sort out what we might use for the `time` portion of the URL, but the `date` part is actually a little more complicated than we might like, as we need to know the specific URL of each injury report we want to download.\n",
    "According to the [official NBA annoucement](https://official.nba.com/nba-injury-report-2020-21-season/), the dates we're interested in are actually the day *before* game days, except on the second days of back-to-backs, in which case presumably the injury report comes out the day of the game.\n",
    "\n",
    "This all sounds complicated, and if there's one thing I've learned about projects like this it's that nothing saps enthusiasm like complication and extra effort that doesn't \"feel\" like it's in the service of what we're trying to  accomplish{% fn 40 %}.\n",
    "\n",
    "So, given what we know, it seems as if we have two options:\n",
    "1. Get a copy of the NBA schedule, and try to download reports for days we know there's a game\n",
    "2. Just start downloading [a range of?] dates and see what we get\n",
    "\n",
    "There's nothing wrong with taking a stab at option 1 here, but this project is about injury reports, not the NBA schedule, so we'll start with option 2{% fn 50 %}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a List of Dates: The Easy Way\n",
    "Programmatically dealing with dates can be [frustrating](https://xkcd.com/1179/), and doing so in Python is no exception.\n",
    "There's a whole rabbit hole we can go down, talking about `timedelta` objects and \"date arithmetic\" et cetera, but let's just cut right to the chase and use `Pandas`.\n",
    "Pandas certainly has its issues, but this is one case where it'll make our lives *much* simpler.\n",
    "\n",
    "So finally...some code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Okay, so that wasn't very satisfying.\n",
    "There's more code coming soon, I promise!)\n",
    "\n",
    "We're going to use the `pandas.date_range` ([docs](https://pandas.pydata.org/docs/reference/api/pandas.date_range.html)) function to generate, well, a range of dates.\n",
    "We'll use these dates as portion of the URL schema detailed above, but in order to do so, we need to know what range to generate.\n",
    "\n",
    "The day before the start of the NBA season until the end of the NBA season seems like a reasonable starting point.\n",
    "If we needed to do this for some number of seasons, we'd want to automate this, but for now, let's just copy the dates manually. \n",
    "Perusing the [wikipedia page](https://en.wikipedia.org/wiki/2020â€“21_NBA_season) for the 2020-2021 NBA season, it looks like the season [started](https://www.espn.com/nba/recap/_/gameId/401266805) on December 22, 2020, and [ended](https://www.youtube.com/watch?v=9O920AD-teU) on July 20th.\n",
    "From manual testing, [https://ak-static.cms.nba.com/referee/injury/Injury-Report_2021-07-20_08PM.pdf](https://ak-static.cms.nba.com/referee/injury/Injury-Report_2021-07-20_08PM.pdf) is a valid link, and the next day, unsurprisingly, is not.\n",
    "\n",
    "Remembering our \"the injury reports can come out the day *before*\" note from above, this gives us our range: `December 21, 2020` through `July 20, 2021`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the [docs](https://pandas.pydata.org/docs/reference/api/pandas.date_range.html) for `pandas.date_range` it there's a ton of parameters we can use, but `start` and `end` look like they might be all we need.\n",
    "Now, for real this time, let's look at some code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2020-21 NBA season started on 2020-12-21 00:00:00, and ended on 2021-07-20 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# This should generate some list-like thing of datetime-like things\n",
    "season_dates = pd.date_range(start='12-21-2020', end='07-20-2021')\n",
    "# Let's look at the first and last dates in our list\n",
    "print(f'The 2020-21 NBA season started on {season_dates[0]}, and ended on {season_dates[-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(It may not look like much, but if you have *any* idea how obnoxious this would be without `pandas`, you'll be impressed!)\n",
    "Now that we have our list of dates, we just need to add them to our URL schema.\n",
    "Let's define variables for the parts of the URL that are static (for now, we may want to download other `report_time` values later):\n",
    "\n",
    "As a reminder, the URL's look like this: \n",
    "> `https://ak-static.cms.nba.com/referee/injury/Injury-Report_2021-07-20_08PM.pdf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't need to define a variable for the extension\n",
    "url_stem = 'https://ak-static.cms.nba.com/referee/injury/Injury-Report_'\n",
    "report_time = '08PM'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's build an example URL, using the first date from the `season_dates` list we created above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ak-static.cms.nba.com/referee/injury/Injury-Report_2020-12-21 00:00:00_08PM.pdf\n"
     ]
    }
   ],
   "source": [
    "print(f'{url_stem}{season_dates[0]}_{report_time}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost, but not quite!\n",
    "It looks like our `season_dates[0]` object is some sort of `datetime`-y type thing.\n",
    "But let's find out what Let's find out exactly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-21 00:00:00 is of type <class 'pandas._libs.tslibs.timestamps.Timestamp'>\n"
     ]
    }
   ],
   "source": [
    "print(f'{season_dates[0]} is of type {type(season_dates[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it's not quite a standard Python `datetime` object ([docs](https://docs.python.org/3/library/datetime.html#datetime.datetime)).\n",
    "But it sure seems like it might behave like one{% fn 60 %}.\n",
    "That being the case, let's just go ahead and try to use the standard method we use to process Python dates into strings: `strftime()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tip: I could never remember which one was which between `strftime` and `strptime` until I leared that `strftime()` is \"string *from* time\" and `strptime()` is \"string *parse* time\" (That sound you hear is the \"The More You Know\" star whoosing by)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our sample URL, it looks like we need things in a `YYYY-MM-DD` format.\n",
    "Luckily, that's a relatively simple format string, but if you want to try it out and be sure, [this interactive site for Python datetime format strings](https://www.strfti.me) is super cool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ak-static.cms.nba.com/referee/injury/Injury-Report_2020-12-21_08PM.pdf\n"
     ]
    }
   ],
   "source": [
    "print(f\"{url_stem}{datetime.strftime(season_dates[0], '%Y-%m-%d')}_{report_time}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: Add note about `from` imports and changing to double-quotes in `f-strings`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success!\n",
    "\n",
    "Now, let's build a list of similarly formatted URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_urls = list()\n",
    "for day in season_dates:\n",
    "    season_urls.append(f\"{url_stem}{datetime.strftime(day, '%Y-%m-%d')}_{report_time}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, if a list comprehension if you prefer (which seems reasonable here, since we're *building* a list):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_urls = [f\"{url_stem}{datetime.strftime(day, '%Y-%m-%d')}_{report_time}.pdf\" for day in season_dates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sanity check the first five URLs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://ak-static.cms.nba.com/referee/injury/Injury-Report_2020-12-21_08PM.pdf',\n",
       " 'https://ak-static.cms.nba.com/referee/injury/Injury-Report_2020-12-22_08PM.pdf',\n",
       " 'https://ak-static.cms.nba.com/referee/injury/Injury-Report_2020-12-23_08PM.pdf',\n",
       " 'https://ak-static.cms.nba.com/referee/injury/Injury-Report_2020-12-24_08PM.pdf',\n",
       " 'https://ak-static.cms.nba.com/referee/injury/Injury-Report_2020-12-25_08PM.pdf']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season_urls[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we're good to go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the PDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity's sake, we'll just use the `requests` module to download the PDFs sequentially.\n",
    "Later, we can see about using *asynchronous* requests to greatly speed up our downloads, but for now let's just do things one at a time.\n",
    "\n",
    "We could do this lazily, with something simple like:\n",
    "```python\n",
    "import requests\n",
    "# Loop through our URL list\n",
    "for url in season_urls:\n",
    "    # Download the PDF\n",
    "    resp = requests.get(url)\n",
    "    # Write to disk; Create a filename from the URL\n",
    "    filename = url.split('/')[-1]\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(resp.content)\n",
    "```\n",
    "\n",
    "With the code above, what happens if there's no report for a specific day?\n",
    "Or if there's a network error, either with the server or our own internet?\n",
    "\n",
    "In general, it's a good idea to program a little defensively when accessing network assets, especially in cases like this, where there's a high likelihood of accessing an \"invalid\" URL (i.e. one with nothing on the other end to download).\n",
    "It's easy to imagine the downstream PDF processing â€” that we haven't written yet ðŸ™‚ â€” breaking when it tries to open an empty file, for example.\n",
    "We could try to handle the error at that point, but it's probably better to do it here, and only write valid files{% fn 70 %}.\n",
    "\n",
    "We'll assume that accessing a URL with a valid injury report on the other end will return [HTTP status code](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes) **200** (\"Success!\"), and one without a PDF will return something else{% fn 80 %}.\n",
    "To handle this, we'll use the `requests` library's `raise_for_status()` method, which can raise an exception when we get a non-success status code.\n",
    "We can then catch that exception, and skip writing the file.\n",
    "\n",
    "Let's add that to the code above:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{{ \"If you're thinking 'You should do both', you get a gold star!\" | fndetail: 100 }}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     " \"Famous last <a href=\"google.com\" target=\"_blank\">words</a>\" | fndetail: 1 ": {}
    }
   },
   "source": [
    "{{ \"Famous last [words](google.com)\" | fndetail: 1 }}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     " \"If you happen to find a central place for these, let me <a href=\"https://www.google.com\" target=\"_blank\">know</a>!\" | fndetail: 2 ": {}
    }
   },
   "source": [
    "{{ \"If you happen to find a central place for these, let me [know](https://www.google.com)!\" | fndetail: 2 }}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     " \"I'm going to try my best to show the provenance of as much insight as I can here.  I had no idea when the injury reports came out, so I googled it.  Don't be ashamed to do likewise if there's something you need to know!\" | fndetail: 30 ": {}
    }
   },
   "source": [
    "{{ \"I'm going to try my best to show the provenance of as much insight as I can here.  I had no idea when the injury reports came out, so I googled it.  Don't be ashamed to do likewise if there's something you need to know!\" | fndetail: 30 }}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     " \"'Decoding the NBA schedule' would certainly be something we could have added to our outline.  This just shows that something as seemingly simple as 'download the PDFs' requires a number of steps that might not be readily apparent!\" | fndetail: 40 ": {}
    }
   },
   "source": [
    "{{ \"'Decoding the NBA schedule' would certainly be something we could have added to our outline.  This just shows that something as seemingly simple as 'download the PDFs' requires a number of steps that might not be readily apparent!\" | fndetail: 40 }}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     " '...and if we happen to run into Adam Silver at a Christmas party, be sure to apologize for the extra traffic on the NBA.com servers' | fndetail: 50 ": {}
    }
   },
   "source": [
    "{{ '...and if we happen to run into Adam Silver at a Christmas party, be sure to apologize for the extra traffic on the NBA.com servers' | fndetail: 50 }}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     " \"The notion that 'something <em>is</em> (e.g.) a list because it behaves like a list' is basically the meaning behind <a href=\"https://realpython.com/lessons/duck-typing/\" target=\"_blank\">Duck Typing</a>\" | fndetail: 60 ": {}
    }
   },
   "source": [
    "{{ \"The notion that 'something is (e.g.) a list because it behaves like a list' is basically the meaning behind [Duck Typing](https://realpython.com/lessons/duck-typing/)\" | fndetail: 60 }}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     " \"If you're thinking 'You should do both', you get a gold star!\" | fndetail: 70 ": {}
    }
   },
   "source": [
    "{{ \"If you're thinking 'You should do both', you get a gold star!\" | fndetail: 70 }}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     " \"From manual inspection of the HTTP headers, it looks like nba.com returns a 403 ('Forbidden') when there isn't a valid PDF\" | fndetail: 80 ": {}
    }
   },
   "source": [
    "{{ \"From manual inspection of the HTTP headers, it looks like nba.com returns a 403 ('Forbidden') when there isn't a valid PDF\" | fndetail: 80 }}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     " \"Or, we could explore the wonderful world of <a href=\"https://www.toptal.com/python/in-depth-python-logging\" target=\"_blank\">logging</a>!\" | fndetail: 90 ": {}
    }
   },
   "source": [
    "{{ \"Or, we could explore the wonderful world of [logging](https://www.toptal.com/python/in-depth-python-logging)!\" | fndetail: 90 }}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     " 'This is the footnote.' | fndetail: 1 ": {},
     " 'This is the other footnote. You can even have a [link](www.github.com)!' | fndetail: 2 ": {}
    }
   },
   "source": [
    "## Footnotes\n",
    "\n",
    "You can have footnotes in notebooks, however the syntax is different compared to markdown documents. [This guide provides more detail about this syntax](https://github.com/fastai/fastpages/blob/master/_fastpages_docs/NOTEBOOK_FOOTNOTES.md), which looks like this:\n",
    "\n",
    "```\n",
    "{% raw %}For example, here is a footnote {% fn 1 %}.\n",
    "And another {% fn 2 %}\n",
    "{{ 'This is the footnote.' | fndetail: 1 }}\n",
    "{{ 'This is the other footnote. You can even have a [link](www.github.com)!' | fndetail: 2 }}{% endraw %}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sports]",
   "language": "python",
   "name": "conda-env-sports-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
